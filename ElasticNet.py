import pandas as pdfrom sklearn.linear_model import LogisticRegressionfrom sklearn import svmfrom sklearn.feature_selection import SelectFromModelfrom sklearn.model_selection import train_test_splitimport numpy as npfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_scorefrom sklearn.tree import DecisionTreeClassifierfrom sklearn.ensemble import RandomForestClassifierfrom sklearn.ensemble import VotingClassifierfrom sklearn.ensemble import AdaBoostClassifierimport matplotlib.pyplot as pltfrom sklearn.feature_selection import SelectKBest, SelectPercentile, chi2from sklearn.linear_model import ElasticNet# Mon DataFrame principalmain_df = pd.read_csv('https://drive.google.com/uc?id=1O4FVHjkQCwduz1a02xZFbtQh8I0v1EsP', sep='\t')# Liste des liens vers les fichiers restantsurls = [    'https://drive.google.com/uc?id=19r82zXqWZg_rp0xpGlNcHc4OQxItgFHX',    'https://drive.google.com/uc?id=1NZ-qP0FX02Whjy5cb4LVlDKuBMXn8YiI',    'https://drive.google.com/uc?id=1KVFQxtDBjLhO-s3vFk8OcyrlJqjJpmAM',    'https://drive.google.com/uc?id=121USCGCctk8k-U5-aHlF7m0byVgrTDuE',    'https://drive.google.com/uc?id=12jRAmwqR25i_jXsEuqFST5-Kyd2cCgbh',    'https://drive.google.com/uc?id=1LeZ_jNFq8bPgV9aLaQY_3FftItbH5u9t',    'https://drive.google.com/uc?id=1nOGlP9jpelIKsZDWaiovvuYvpwkL35OQ',    'https://drive.google.com/uc?id=1sJ0_aaviYLkH4yqZ9X8i8Gm8X5_NHh12',    'https://drive.google.com/uc?id=1tXZdO-z80-N1y7jcxARSITGznTs-fxyv',    'https://drive.google.com/uc?id=1IodxiSiMifPoFR6AyR8BqWkz05fAueys',    'https://drive.google.com/uc?id=1KJjjTiTsmM6K1yfjQsvZRrs7Loc-e-UG',    'https://drive.google.com/uc?id=1AbAD2WhF2eg-lUqCv3BcXvuZ_DjJb9Vo',    'https://drive.google.com/uc?id=1giq4_IFHyK_XerPR3WHZW-qvI-z0xDxQ',    'https://drive.google.com/uc?id=15xMITPd4O2WNwUThxXkl6tHOqq-sA65X',    'https://drive.google.com/uc?id=1HwascUUEPl6sHuV_Zxst8axYRhyt6nU5',    'https://drive.google.com/uc?id=165y-VGGVQiYJCGqjsEPWF-zucw0rLrTD',    'https://drive.google.com/uc?id=1PuIKLrjmn-b6u7weXl4TPOmTuyIJ1blL',    'https://drive.google.com/uc?id=1s6yNL1w0nZjjNjmPdQ_T4xXFnDUZWqIT']# Jointure par lot avec chaque fichierfor url in urls:    chunk_df = pd.read_csv(url, sep='\t')  # Chargez un DataFrame à la fois    main_df = pd.merge(main_df, chunk_df, on='ID', how='outer')  # Effectuez la jointure    del chunk_df  # Libérez la mémoire du DataFrame chargé#==============================================================================================================# Lien des phénotypes partagé direct du fichier Google Driveurl = 'https://drive.google.com/uc?id=1B0_OYAeq5Y5cSIYCl3MGBKmxOw-fjWQu'# Charger le fichier CSV directement depuis le lien Google Drivepheno = pd.read_csv(url, sep='\t')pheno= pheno[["ID", "Smoking_status"]]# Jointure des données SNP et phénotype sur la colonne "ID"main_df = main_df.merge(pheno, on="ID")# Supprimer les lignes où la dernière colonne est égale à -1main_df = main_df[main_df.iloc[:, -1] != -1]#==============================================================================================================# Supprimer les lignes où la dernière colonne est égale à -1main_df = main_df[main_df.iloc[:, -1] != -1]not_col= ["ID", "Smoking_status"]df = pd.get_dummies(data= main_df, columns= [col for col in main_df.columns if col not in not_col])#==============================================================================================================#X = df.iloc[:, 2:]scaled_features = df.iloc[:, 2:]labels=df.iloc[:, 1]# Diviser les données en ensembles d'entraînement et de testtrain_features, test_features, train_labels, test_labels = train_test_split(scaled_features, labels, test_size=0.2, random_state=42)#==============================================================================================================# Créer et entraîner le modèle Elastic Net# Vous pouvez ajuster les paramètres alpha et l1_ratio selon vos besoinsmodel_en = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)model_en.fit(train_features, train_labels)#==============================================================================================================# Obtenir les coefficients du modèlecoefficients = model_en.coef_# Sélectionner les caractéristiques avec des coefficients non nulsselected_features = scaled_features.columns[:][coefficients != 0]#==============================================================================================================list_feature=selected_features.tolist()scaled_features_selected = scaled_features[list_feature]# Diviser les données en ensembles d'entraînement et de testtrain_features, test_features, train_labels, test_labels = train_test_split(scaled_features_selected, labels, test_size=0.2, random_state=42)#==============================================================================================================# Utiliser encoded_features pour l'entraînement de la Logistic Regressionmodel_LR = LogisticRegression(max_iter=10000, random_state=42)model_LR.fit(train_features, train_labels)#==============================================================================================================# Prédire les étiquettes sur les données de testpredictions = model_LR.predict(test_features)# Calculer la précision du modèle sur les données de testaccuracy = accuracy_score(test_labels, predictions)print(f"Accuracy on test set: {accuracy}")